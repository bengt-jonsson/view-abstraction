\section{Introduction}


%% One of the most difficult current challenges in
%% software verification is to automate its
%% application to 

Concurrent algorithms with an unbounded number of
threads that concurrently access a dynamically allocated shared state
are of central importance in a large number of software systems.
They provide efficient concurrent realizations of
common interface abstractions, and
are widely used in libraries,
such as the Intel Threading Building Blocks or
the \url{java.util.concurrent} package.
They are notoriously difficult to get correct and verify, since they
often employ fine-grained synchronization and avoid locking when
possible. A number of bugs  in published
algorithms have been reported~\cite{DDGJLMMSS:dcas,MiSc:correction}.
Consequently, significant research efforts have been directed towards developing
techniques to verify correctness of such algorithms. One important use
of such techniques is
to verify that concurrent algorithms that implement standard data structure
interfaces are {\em linearizable}, meaning that
each method invocation can be considered to occur atomically at some point
between its call and return.
Many of the developed verification techniques require significant
{\em manual} effort for constructing correctness proofs
(e.g.,~\cite{LF:pldi13,Vafeiadis:Thesis}),
in some cases with the support of an interactive theorem prover
(e.g.,~\cite{Aaron:logical:linearizability,Colvin:Lazy-List,Derrick:fm14,SWD:cav12,SDW:tcl14}).
Development of automated verification techniques remains a difficult challenge.

A major challenge for the development of automated verification techniques
is that such techniques must be
able to reason about fine-grained concurrent algorithms that are infinite-state
in many dimensions:
they consist of an unbounded number of concurrent threads, which
operate on an unbounded domain of data values, and use
unbounded dynamically allocated memory. 
Perhaps the hardest of these challenges is that of handling 
dynamically allocated memory.
Consequently, existing techniques that can automatically prove correctness
of such fine-grained concurrent algorithms restrict attention to the simple
case where heap structures represent shared data by singly-linked 
%% All automated approaches restrict attention to concurrent algorithms in which
lists~\cite{AHHR:integrated,meyer:vmcai16,Quy:sas16,Sagiv:correlation,Vafeiadis:cav10}. Furthermore, many of these techniques impose additional restrictions on the considered verification problem, such as bounding the number of accessing
threads~\cite{Amit:comparisonAbstraction,Vechev:spin09,CernyRZCA:CAV10}.
\bjcom{Add other restrictions}
However, in many concurrent data structure implementations the heap represents
more sophisticated structures, such as 
skiplists~\cite{Fomitchev:2004,ArtOfMpP,Sundell:2005} and arrays of
of singly-linked lists~\cite{ts-stack}. There are no
techniques that have been applied to automatically verify concurrent algorithms
that operate on such data structures.

%% \cite{HSV:concur13,Vafeiadis:cav10},
%% or requiring auxiliary lemmas
%% \cite{OHearnlist,Poling}.}
\todo[inline]{The list of description of restrictions of SSL work must be improved. We actually should be more precise about what previous work has achieved, in terms of which combinations of challenges have been overcome}

\paragraph{Contributions}
In this paper, we present a technique for automatic verification of concurrent
data structure implementations that operate on dynamically allocated
heap structures which are more complex than just singly-linked lists.
Our approach is the first framework that
can automatically verify concurrent data structure implementations that
singly linked lists, skip lists~\cite{Fomitchev:2004,ArtOfMpP,Sundell:2005},
as well as arrays of singly linked lists~\cite{ts-stack},
at the same time as handling an unbounded
number of concurrent threads, an unbounded domain of data values
(including timestamps), and an unbounded shared heap.

%% thereby abstracting away from the correlation between local states of different threads.
Our technique is based on a novel shape abstraction,
called {\em fragment abstraction}, which in a simple and uniform way is able to
represent different kinds of unbounded heap structures.
%% such as skip lists and arrays of singly linked lists.
Its main idea is to represent a set of heap states by a set of {\em fragments}.
A fragment consists of a pair of heap cells that are connected by a pointer field.
For each of its cells, the fragment represents
the values of its non-pointer
fields as well as information about how it can be reached from pointer
variables. The latter information is both {\em local}, saying which pointer
variables point directly to the cell, and {\em global}, saying how the
cell can reach to and be reached from (by following chains of pointers)
other heap cells that are pointed to by global variables.
A set of fragments represents the set of heap
structures in which each pair of pointer-connected nodes are represented by some
fragment in the set.
Inuitively, a set of fragments describes the set of heaps that can be formed by
``pieced together'' fragments in the set.
%% This ``piecing together'' must
%% be both locally consistent (appending only fragments that agree on their
%% common node), and globally consistent (respecting the global reachability
%% information).
The combination of local and global information in fragments allows the
verification to reason about the sequence of cells that can be ``seen'' by
threads as they traverse the heap by following pointer fields in cells and
pointer variables, thereby enabling automatic verification of reachability
properties. The local information captures which cell patterns may be
seen while traversing the heap, whereas the global information also
captures whether certain accesses (also by other threads) will be possible
in the future. 

Fragment abstraction can and should be, in a natural way,
be combined with data abstractions for
handling unbounded data domains and with thread abstractions
for handling an unbounded number of threads.
For the latter we adapt
the successful thread-modular approach~\cite{BLMRS:cav08}, which constructs
a representation of the local state of a single, but arbitrary thread, together
with part of the global state and heap that is accessible to that thread.
Our combination of fragment abstraction, thread abstraction, and data
abstraction results in a finite abstract domain, thereby guaranteeing
termination of our analysis.

%% Our fragment abstraction technique copes with an unbounded data domain by
%% letting the definition of tags incorporate
%% a suitable data abstraction to the data fields in heap nodes.
%% For instance, timestamp fields can be handles by applying
%% an abstraction which records the relation between a timestamp value and the values of global timestamp variables.
%% \bjcom{The last sentence was not completely accurate}

%% representation of a particular heap is obtained as the set of pairs of nodes
%% that are connected by a {\tt next pointer}. Conversely,
%% a set of (heap) fragments represents the set of heaps that can be formed by
%% putting together fragments from this set, where each fragment may be used
%% multiple times. In order to obtain a representation which is both expressive
%% and bounded, nodes are first abstracted to a finite set of node types, called
%% {\em tags}. A tag represents both local information about the values of
%% fields of the node
%% and about which pointer variables point to the node, as well as global
%% information about how the node is positioned in the overall projected heap.
%% The global information records from which global and thread-local pointer
%% variables the node can be reached by a sequence of pointers, as well as
%% which global variables can be reached from the node.
%% \bjcom{I believe we could omit this last sentence}

%% \bjcom{Here is just some text to be developed}
%% In this abstraction, one first defines a
%% set of {\em tags}. Intuitively, a tag is a predicate on nodes in a heap,
%% which consists of constraints on the values of its fields, and lists
%% the set of pointer variables that point directly to the node, or that point
%% to a node that can reach or be reached from the node by a sequence of
%% {\tt next} pointers. Thus, for each program the set of tags is bounded.
%% The heap structure is then represented by a set of {\em fragments}. Each
%% fragment is a pair of tags, such that each pair of nodes in the
%% projection of the heap onto a particular thread is represented by some
%% fragment.


%% It is well understood how to
%% accomplish this for finite-state programs (as embodied, e.g., in
%% the SPIN tool~\cite{Holzmann:spin}),
%% but we lack approaches for handling unbounded data domains in specifications
%% and implementations in connection with an unbounded number of threads and
%% dynamically allocated data structures.

We have implemented our approach and applied it to automatically verify
correctness, in the sense of linearizability, of a large number of
concurrent data structure algorithms.
More specifically, we have automatically verified linearizability of 
most linearizable concurrent implementations
of sets, stacks, and queues, which emply singly-linked lists, skip lists, or
arrays of timestamped singly-linked lists, which are known to us in
the literature on concurrent data structures.

For this verification, we we specify linearizability
using the simple and powerful technique of
{\em observers}~\cite{AHHR:integrated,BEEH:icalp15,HSV:concur13,Quy:sas16},
which can be seen as monitors that
report violations of the linearizability criterion. Observers synchronize with
the monitored concurrent programs at designated actions. This can be done in
two ways.
\begin{inparaenum}[(1)]
\item
  For concurrent implementations of stacks and queues,
  linearizability can be precisely specified by
  observers that synchronize on call and return actions of
  methods, as shown by~\cite{BEEH:icalp15,HSV:concur13}; this is done without
 any user annotation.
\item
  For sets, the verification requires the user to annotate how linearization
  points are placed in each method; in most cases this is a small burden for
  the verifier. The observer then synchronizeson these 
  linearization points.
%% typically by affixing
%%   linearization points to particular statements, or in more complex cases by
%%   light-weight instrumentation using the approach of
%%   controllers~\cite{Quy:sas16}.
%% \item
%%   For sets, the verification requires the user to annotate how linearization
%%   points are placed in each method, typically by affixing
%%   linearization points to particular statements, or in more complex cases by
%%   light-weight instrumentation using the approach of
%%   controllers~\cite{Quy:sas16}.
\end{inparaenum}
Our implementation then automatically checks, using our novel technique based on
fragment abstraction, that a supplied C-like description of a concurrent data structure is a correct linearizable implementation of a stack, queue, or set.

The fact that our fragment abstraction has been able to automatically verify all
suppplied concurrent algorithms, also those that employ skiplists or
arrays of SLLs, indicates that the fragment abstraction is a simple
mechanism for capturing both the local and global information about heap cells
that is necessary for verifying correctness, in particular for
concurrent algorithms where an unbounded number of threads interact
via a shared heap.

\todo[inline]{Here goes the outline}
