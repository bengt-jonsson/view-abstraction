\section{Introduction}


%% One of the most difficult current challenges in
%% software verification is to automate its
%% application to 

Concurrent algorithms with an unbounded number of
threads that concurrently access a dynamically allocated shared state
are of central importance in a large number of software systems.
They provide efficient concurrent realizations of
common interface abstractions, and
are widely used in libraries,
such as the Intel Threading Building Blocks or
the \url{java.util.concurrent} package.
They are notoriously difficult to get correct and verify, since they
often employ fine-grained synchronization and avoid locking when
possible. A number of bugs  in published
algorithms have been reported~\cite{DDGJLMMSS:dcas,MiSc:correction}.
Consequently, significant research efforts have been directed towards developing
techniques to verify correctness of such algorithms.
%% One important use of such techniques is
%% to verify that concurrent algorithms that implement standard data structure
%% interfaces are {\em linearizable},
One widely-used correctness criterion is that of {\em linearizability},
meaning that each method invocation can be considered to occur atomically at some point
between its call and return.
Many of the developed verification techniques require significant
{\em manual} effort for constructing correctness proofs
(e.g.,~\cite{LF:pldi13,Vafeiadis:Thesis}),
in some cases with the support of an interactive theorem prover
(e.g.,~\cite{Aaron:logical:linearizability,Colvin:Lazy-List,SDW:tcl14}).
Development of automated verification techniques remains a difficult challenge.

A major challenge for the development of automated verification techniques
is that such techniques must be
able to reason about fine-grained concurrent algorithms that are infinite-state
in many dimensions:
they consist of an unbounded number of concurrent threads, which
operate on an unbounded domain of data values, and use
unbounded dynamically allocated memory. 
Perhaps the hardest of these challenges is that of handling 
dynamically allocated memory.
Consequently, existing techniques that can automatically prove correctness
of such fine-grained concurrent algorithms restrict attention to the
case where heap structures represent shared data by singly-linked 
%% All automated approaches restrict attention to concurrent algorithms in which
lists~\cite{AHHR:integrated,meyer:vmcai16,Quy:sas16,Sagiv:correlation,Vafeiadis:cav10}. Furthermore, many of these techniques impose additional restrictions on the considered verification problem, such as bounding the number of accessing
threads~\cite{Amit:comparisonAbstraction,Vechev:spin09,CernyRZCA:CAV10}.
However, in many concurrent data structure implementations the heap represents
more sophisticated structures, such as 
skiplists~\cite{Fomitchev:2004,ArtOfMpP,Sundell:2005} and arrays of
of singly-linked lists~\cite{ts-stack}. There are no
techniques that have been applied to automatically verify concurrent algorithms
that operate on such data structures.

%% \cite{HSV:concur13,Vafeiadis:cav10},
%% or requiring auxiliary lemmas
%% \cite{OHearnlist,Poling}.}
%% \todo[inline]{The list of description of restrictions of SSL work must be improved. We actually should be more precise about what previous work has achieved, in terms of which combinations of challenges have been overcome}

\vspace*{-0.6cm}
\paragraph{Contributions}
In this paper, we present a technique for automatic verification of concurrent
data structure implementations that operate on dynamically allocated
heap structures which are more complex than just singly-linked lists.
Our framework is the first that
can automatically verify concurrent data structure implementations that employ
singly linked lists, skiplists~\cite{Fomitchev:2004,ArtOfMpP,Sundell:2005},
as well as arrays of singly linked lists~\cite{ts-stack},
at the same time as handling an unbounded
number of concurrent threads, an unbounded domain of data values
(including timestamps), and an unbounded shared heap.

%% thereby abstracting away from the correlation between local states of different threads.
Our technique is based on a novel shape abstraction,
called {\em fragment abstraction}, which in a simple and uniform way is able to
represent several different classes of unbounded heap structures.
%% such as skiplists and arrays of singly linked lists.
Its main idea is to represent a set of heap states by a set of {\em fragments}.
A fragment represents two heap cells that are connected by a pointer field.
For each of its cells, 
the fragment represents the contents of its non-pointer fields, together with
information about how the cell can be reached from the program's global pointer
variables. The latter information consists of both:
\begin{inparaenum}[(i)]
  \item {\em local} information, saying which pointer variables
    point directly to them, and
    \item {\em global} information, saying how the cell
      can reach to and be reached from (by following chains of pointers)
      heap cells that are globally significant, typically since
      some global variable points to them.
\end{inparaenum}
A set of fragments represents the set of heap states
in which any two pointer-connected nodes is represented by some
fragment in the set.
Thus, a set of fragments describes the set of heaps that can be formed by
``piecing together'' fragments in the set.
%% This ``piecing together'' must
%% be both locally consistent (appending only fragments that agree on their
%% common node), and globally consistent (respecting the global reachability
%% information).
The combination of local and global information in fragments supports
reasoning about the sequence of cells that can be accessed by
threads that traverse the heap by following pointer fields in cells and
pointer variables:
the local information captures properties of the cell fields that can
be accessed as a thread dereferences a pointer variable or a pointer field;
the global information also captures whether certain significant accesses
will at all be possible by following a sequence of pointer fields.
This support for reasoning about patterns of cell accesses enables
automated verification of reachability and other functional properties.

Fragment abstraction can (and should) be combined, in a natural way,
with data abstractions for
handling unbounded data domains and with thread abstractions
for handling an unbounded number of threads.
For the latter we adapt
the successful thread-modular approach~\cite{BLMRS:cav08}, which
represents the local state of a single, but arbitrary thread, together
with the part of the global state and heap that is accessible to that thread.
Our combination of fragment abstraction, thread abstraction, and data
abstraction results in a finite abstract domain, thereby guaranteeing
termination of our analysis.

%% Our fragment abstraction technique copes with an unbounded data domain by
%% letting the definition of tags incorporate
%% a suitable data abstraction to the data fields in heap nodes.
%% For instance, timestamp fields can be handles by applying
%% an abstraction which records the relation between a timestamp value and the values of global timestamp variables.
%% \bjcom{The last sentence was not completely accurate}

%% representation of a particular heap is obtained as the set of pairs of nodes
%% that are connected by a {\tt next pointer}. Conversely,
%% a set of (heap) fragments represents the set of heaps that can be formed by
%% putting together fragments from this set, where each fragment may be used
%% multiple times. In order to obtain a representation which is both expressive
%% and bounded, nodes are first abstracted to a finite set of node types, called
%% {\em tags}. A tag represents both local information about the values of
%% fields of the node
%% and about which pointer variables point to the node, as well as global
%% information about how the node is positioned in the overall projected heap.
%% The global information records from which global and thread-local pointer
%% variables the node can be reached by a sequence of pointers, as well as
%% which global variables can be reached from the node.
%% \bjcom{I believe we could omit this last sentence}

%% \bjcom{Here is just some text to be developed}
%% In this abstraction, one first defines a
%% set of {\em tags}. Intuitively, a tag is a predicate on nodes in a heap,
%% which consists of constraints on the values of its fields, and lists
%% the set of pointer variables that point directly to the node, or that point
%% to a node that can reach or be reached from the node by a sequence of
%% {\tt next} pointers. Thus, for each program the set of tags is bounded.
%% The heap structure is then represented by a set of {\em fragments}. Each
%% fragment is a pair of tags, such that each pair of nodes in the
%% projection of the heap onto a particular thread is represented by some
%% fragment.


%% It is well understood how to
%% accomplish this for finite-state programs (as embodied, e.g., in
%% the SPIN tool~\cite{Holzmann:spin}),
%% but we lack approaches for handling unbounded data domains in specifications
%% and implementations in connection with an unbounded number of threads and
%% dynamically allocated data structures.

We have implemented our approach and applied it to automatically verify
correctness, in the sense of linearizability, of a large number of
concurrent data structure algorithms, described in a C-like language.
More specifically, we have automatically verified linearizability of 
most linearizable concurrent implementations
of sets, stacks, and queues, and priority queues,
which employ singly-linked lists, skiplists, or
arrays of timestamped singly-linked lists, which are known to us in
the literature on concurrent data structures.
For this verification, we specify linearizability
using the simple and powerful technique of
{\em observers}~\cite{AHHR:integrated,BEEH:icalp15,HSV:concur13},
which reduces the criterion of linearizability to a simple reachability
property. To verify implementations of stacks and queues, 
the application of observers can be done completely automatically without
any manual steps, whereas for implementations of sets, the verification relies
on light-weight user annotation of how linearization points are placed in
each method~\cite{Quy:sas16},.
%% report violations of the linearizability criterion. Observers synchronize with
%% the monitored concurrent programs at designated actions. This can be done in
%% two ways.
%% \begin{inparaenum}[(1)]
%% \item
%%   For concurrent implementations of stacks and queues,
%%   linearizability can be precisely specified by
%%   observers that synchronize on call and return actions of
%%   methods, as shown by~\cite{BEEH:icalp15,HSV:concur13}; this is done without
%%  any user annotation.
%% \item
%%   For sets, the verification requires the user to annotate how linearization
%%   points are placed in each method; in most cases this is a small burden for
%%   the verifier. The observer then synchronizeson these 
%%   linearization points.
%% typically by affixing
%%   linearization points to particular statements, or in more complex cases by
%%   light-weight instrumentation using the approach of
%%   controllers~\cite{Quy:sas16}.
%% \item
%%   For sets, the verification requires the user to annotate how linearization
%%   points are placed in each method, typically by affixing
%%   linearization points to particular statements, or in more complex cases by
%%   light-weight instrumentation using the approach of
%%   controllers~\cite{Quy:sas16}.
%% \end{inparaenum}
%% Our implementation then automatically checks, using our novel technique based on
%% fragment abstraction, that a supplied C-like description of a concurrent data structure is a correct linearizable implementation of a stack, queue, or set.

The fact that our fragment abstraction has been able to automatically verify all
supplied concurrent algorithms, also those that employ skiplists or
arrays of SLLs, indicates that the fragment abstraction is a simple
mechanism for capturing both the local and global information about heap cells
that is necessary for verifying correctness, in particular for
concurrent algorithms where an unbounded number of threads interact
via a shared heap.

\paragraph{Outline}
In the next section, we illustrate our fragment abstraction on the
verification of a skiplist-based concurrent set implementation.
In Section~\ref{programs:section} we introduce our model for programs,
and of observers for specifying linearizability. In 
Section~\ref{sec:fragment-abstraction} we describe in more detail our
fragment abstraction for skiplists; note that singly-linked lists can
be handled as a simple special case of skiplists.
In Section~\ref{sec:ts} we describe how fragment abstraction applies to
arrays of singly-linked lists with timestamp fields.
Our implementation and
experiments are reported in Section~\ref{section:experiments}, followed
by conclusions in Section~\ref{sec:conclusions}.




